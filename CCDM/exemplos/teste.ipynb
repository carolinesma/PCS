{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0498741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amplitude probabilities (shaped vs uniform)    amplitude  P_shaped  P_uniform\n",
      "0          1      0.50   0.333333\n",
      "1          3      0.25   0.333333\n",
      "2          5      0.25   0.333333\n",
      "       sequence bits_from_inverse\n",
      "0  (1, 1, 3, 5)               000\n",
      "1  (1, 1, 5, 3)               001\n",
      "2  (1, 3, 1, 5)               010\n",
      "3  (1, 3, 5, 1)               011\n",
      "4  (1, 5, 1, 3)               100\n",
      "5  (1, 5, 3, 1)               101\n",
      "6  (3, 1, 1, 5)               110\n",
      "7  (3, 1, 5, 1)               111\n",
      "Toy CCDM example: alphabet=[1, 3, 5], composition=[2, 1, 1], block length n=4\n",
      "Total distinct sequences with that composition: 12\n",
      "We map k=3 bits -> 8 sequences (first 8 lexicographically) and leave 4 sequences unused.\n",
      "Average symbol energy (shaped) = 9.000, (uniform) = 11.667  -> shaped reduces average energy by 2.667.\n",
      "Entropy per amplitude: shaped = 1.500 bits, uniform = 1.585 bits.\n",
      "\n",
      "Notes:\n",
      "- This mapping is invertible for the used sequences (we showed sequence->bits inversion for mapped sequences).\n",
      "- Practical CCDM uses large blocks & efficient enumerative coding to approach the target distribution with smaller rate loss.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CCDM example: small-block enumerative CCDM mapping (brute-force enumeration)\n",
    "# This code demonstrates a simple CCDM that maps k bits -> a sequence of amplitudes\n",
    "# with *constant composition* (multiset permutations). It's suitable for small block sizes.\n",
    "#\n",
    "# We:\n",
    "#  - define an amplitude alphabet (e.g., [1, 3, 5])\n",
    "#  - choose a composition (counts per amplitude) summing to block length n\n",
    "#  - enumerate all distinct sequences with that composition, sort lexicographically\n",
    "#  - map the first 2^k sequences to k-bit input words (k = floor(log2(num_sequences)))\n",
    "#  - show mapping table, probabilities, average energy comparison with uniform QAM-like mapping\n",
    "#\n",
    "# NOTE: This is a pedagogical example; practical CCDM implementations use efficient enumerative\n",
    "# algorithms for larger block lengths (e.g., arithmetic coding / enumerative coding).\n",
    "\n",
    "from itertools import permutations\n",
    "import pandas as pd\n",
    "from math import log2, floor, factorial\n",
    "from collections import Counter\n",
    "\n",
    "# Parameters for the toy example\n",
    "alphabet = [1, 3, 5]           # amplitude levels\n",
    "composition = [2, 1, 1]        # counts for each amplitude, sums to n = 4\n",
    "n = sum(composition)\n",
    "\n",
    "# Generate all distinct permutations of the multiset defined by (alphabet, composition)\n",
    "multiset = []\n",
    "for a, c in zip(alphabet, composition):\n",
    "    multiset += [a] * c\n",
    "\n",
    "# Use set(permutations(...)) to get distinct arrangements\n",
    "all_seqs = sorted(set(permutations(multiset, n)))\n",
    "\n",
    "num_sequences = len(all_seqs)\n",
    "k = floor(log2(num_sequences))  # number of input bits we can map losslessly (integer)\n",
    "num_mapped = 2**k                # number of sequences we will use (power of two)\n",
    "unused = num_sequences - num_mapped\n",
    "\n",
    "# Prepare mapping: map binary words 0..2^k-1 to the first 2^k sequences\n",
    "mapping = []\n",
    "for idx in range(num_mapped):\n",
    "    bits = format(idx, f'0{k}b')\n",
    "    seq = all_seqs[idx]\n",
    "    mapping.append({'bits': bits, 'sequence': seq})\n",
    "\n",
    "df = pd.DataFrame(mapping)\n",
    "# compute amplitude distribution from mapped sequences (each sequence equally likely)\n",
    "amp_counts = Counter()\n",
    "for row in df['sequence']:\n",
    "    amp_counts.update(row)\n",
    "amp_prob = {a: amp_counts[a] / (num_mapped * n) for a in alphabet}\n",
    "\n",
    "# For comparison: uniform distribution over the same alphabet (naive uniform over amplitudes)\n",
    "uniform_prob = {a: 1/len(alphabet) for a in alphabet}\n",
    "\n",
    "# Compute average symbol energy (E = amplitude^2) for shaped vs uniform\n",
    "E_shaped = sum((a**2) * p for a, p in amp_prob.items())\n",
    "E_uniform = sum((a**2) * p for a, p in uniform_prob.items())\n",
    "\n",
    "# Entropy per amplitude for shaped distribution (bits of information per amplitude symbol)\n",
    "import math\n",
    "H_shaped = -sum(p*math.log2(p) for p in amp_prob.values() if p>0)\n",
    "H_uniform = -sum(p*math.log2(p) for p in uniform_prob.values() if p>0)\n",
    "\n",
    "# Create a summary table\n",
    "summary = pd.DataFrame([\n",
    "    {'Distribution': 'CCDM-shaped (mapped)', 'num_sequences': num_sequences, 'mapped_sequences': num_mapped,\n",
    "     'k_bits': k, 'unused_sequences': unused, \n",
    "     'E_avg': E_shaped, 'H_per_amp_bits': H_shaped},\n",
    "    {'Distribution': 'Uniform (naive)', 'num_sequences': 'N/A', 'mapped_sequences': 'N/A',\n",
    "     'k_bits': 'N/A', 'unused_sequences': 'N/A', \n",
    "     'E_avg': E_uniform, 'H_per_amp_bits': H_uniform},\n",
    "])\n",
    "\n",
    "# Display mapping and summary\n",
    "# from caas_jupyter_tools import display_dataframe_to_user\n",
    "# display_dataframe_to_user(\"CCDM Mapping Table (first mapped sequences)\", df)\n",
    "# display_dataframe_to_user(\"Summary: energies and entropies\", summary)\n",
    "\n",
    "# Also print the amplitude probabilities\n",
    "amp_table = pd.DataFrame([{'amplitude': a, 'P_shaped': amp_prob[a], 'P_uniform': uniform_prob[a]} for a in alphabet])\n",
    "print(\"Amplitude probabilities (shaped vs uniform)\", amp_table)\n",
    "\n",
    "# Finally show how to invert: recover bits from a given sequence by lookup\n",
    "def sequence_to_bits(sequence):\n",
    "    try:\n",
    "        idx = all_seqs.index(tuple(sequence))\n",
    "    except ValueError:\n",
    "        return None  # sequence not in the enumerated set\n",
    "    if idx < num_mapped:\n",
    "        return format(idx, f'0{k}b')\n",
    "    else:\n",
    "        return None  # this sequence isn't used by our mapping (unused sequences)\n",
    "\n",
    "# Demonstrate inversion on mapped sequences\n",
    "inversion_demo = []\n",
    "for _, row in df.iterrows():\n",
    "    inversion_demo.append({'sequence': row['sequence'], 'bits_from_inverse': sequence_to_bits(row['sequence'])})\n",
    "print(pd.DataFrame(inversion_demo))\n",
    "\n",
    "# Print a small explanatory note for the user\n",
    "print(\n",
    "    f\"Toy CCDM example: alphabet={alphabet}, composition={composition}, block length n={n}\\n\"\n",
    "    f\"Total distinct sequences with that composition: {num_sequences}\\n\"\n",
    "    f\"We map k={k} bits -> {num_mapped} sequences (first {num_mapped} lexicographically) and leave {unused} sequences unused.\\n\"\n",
    "    f\"Average symbol energy (shaped) = {E_shaped:.3f}, (uniform) = {E_uniform:.3f}  -> shaped reduces average energy by {E_uniform - E_shaped:.3f}.\\n\"\n",
    "    f\"Entropy per amplitude: shaped = {H_shaped:.3f} bits, uniform = {H_uniform:.3f} bits.\\n\\n\"\n",
    "    \"Notes:\\n\"\n",
    "    \"- This mapping is invertible for the used sequences (we showed sequence->bits inversion for mapped sequences).\\n\"\n",
    "    \"- Practical CCDM uses large blocks & efficient enumerative coding to approach the target distribution with smaller rate loss.\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df8332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição MB alvo:\n",
      "  A=1, P=0.649\n",
      "  A=3, P=0.292\n",
      "  A=5, P=0.059\n",
      "\n",
      "Composição escolhida para n=6: [4, 2, 0]\n",
      "\n",
      "Total de sequências possíveis: 15\n",
      "Bits mapeados por bloco: k=3 (8 sequências usadas, 7 não usadas)\n",
      "\n",
      "Tabela de mapeamento (primeiros bits -> sequência):\n",
      "  bits            sequence\n",
      "0  000  (1, 1, 1, 1, 3, 3)\n",
      "1  001  (1, 1, 1, 3, 1, 3)\n",
      "2  010  (1, 1, 1, 3, 3, 1)\n",
      "3  011  (1, 1, 3, 1, 1, 3)\n",
      "4  100  (1, 1, 3, 1, 3, 1)\n",
      "5  101  (1, 1, 3, 3, 1, 1)\n",
      "6  110  (1, 3, 1, 1, 1, 3)\n",
      "7  111  (1, 3, 1, 1, 3, 1)\n",
      "\n",
      "Probabilidades obtidas (shaped vs uniforme):\n",
      "A=1: shaped=0.667, uniform=0.333\n",
      "A=3: shaped=0.333, uniform=0.333\n",
      "A=5: shaped=0.000, uniform=0.333\n",
      "\n",
      "Energia média shaped = 3.667\n",
      "Energia média uniforme = 11.667\n",
      "Redução de energia = 8.000\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "from math import exp, floor, log2\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# --- 1. Amplitudes e distribuição MB ---\n",
    "alphabet = [1, 3, 5]\n",
    "lambda_param = 0.1  # controla \"força\" do shaping\n",
    "\n",
    "# Maxwell-Boltzmann: P(a) ∝ e^(-lambda * a^2)\n",
    "mb_weights = [exp(-lambda_param * a**2) for a in alphabet]\n",
    "Z = sum(mb_weights)\n",
    "mb_probs = [w / Z for w in mb_weights]\n",
    "\n",
    "print(\"Distribuição MB alvo:\")\n",
    "for a, p in zip(alphabet, mb_probs):\n",
    "    print(f\"  A={a}, P={p:.3f}\")\n",
    "\n",
    "# --- 2. Escolha da composição constante ---\n",
    "n = 6  # tamanho do bloco (pequeno para visualização)\n",
    "target_counts = [round(p * n) for p in mb_probs]\n",
    "# Ajuste para garantir que soma seja n\n",
    "while sum(target_counts) != n:\n",
    "    diff = n - sum(target_counts)\n",
    "    target_counts[target_counts.index(max(target_counts))] += diff\n",
    "\n",
    "print(f\"\\nComposição escolhida para n={n}: {target_counts}\")\n",
    "\n",
    "# --- 3. Gerar todas as permutações com essa composição ---\n",
    "multiset = []\n",
    "for a, c in zip(alphabet, target_counts):\n",
    "    multiset += [a] * c\n",
    "\n",
    "all_seqs = sorted(set(permutations(multiset, n)))\n",
    "num_sequences = len(all_seqs)\n",
    "k = floor(log2(num_sequences))\n",
    "num_mapped = 2**k\n",
    "unused = num_sequences - num_mapped\n",
    "\n",
    "print(f\"\\nTotal de sequências possíveis: {num_sequences}\")\n",
    "print(f\"Bits mapeados por bloco: k={k} ({num_mapped} sequências usadas, {unused} não usadas)\")\n",
    "\n",
    "# --- 4. Mapear bits -> sequências ---\n",
    "mapping = []\n",
    "for idx in range(num_mapped):\n",
    "    bits = format(idx, f'0{k}b')\n",
    "    seq = all_seqs[idx]\n",
    "    mapping.append({'bits': bits, 'sequence': seq})\n",
    "\n",
    "df = pd.DataFrame(mapping)\n",
    "print(\"\\nTabela de mapeamento (primeiros bits -> sequência):\")\n",
    "print(df)\n",
    "\n",
    "# --- 5. Comparar distribuição e energia ---\n",
    "amp_counts = Counter()\n",
    "for seq in df['sequence']:\n",
    "    amp_counts.update(seq)\n",
    "amp_prob_shaped = {a: amp_counts[a] / (num_mapped * n) for a in alphabet}\n",
    "amp_prob_uniform = {a: 1/len(alphabet) for a in alphabet}\n",
    "\n",
    "E_shaped = sum((a**2) * p for a, p in amp_prob_shaped.items())\n",
    "E_uniform = sum((a**2) * p for a, p in amp_prob_uniform.items())\n",
    "\n",
    "print(\"\\nProbabilidades obtidas (shaped vs uniforme):\")\n",
    "for a in alphabet:\n",
    "    print(f\"A={a}: shaped={amp_prob_shaped[a]:.3f}, uniform={amp_prob_uniform[a]:.3f}\")\n",
    "\n",
    "print(f\"\\nEnergia média shaped = {E_shaped:.3f}\")\n",
    "print(f\"Energia média uniforme = {E_uniform:.3f}\")\n",
    "print(f\"Redução de energia = {E_uniform - E_shaped:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd852a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pcs)",
   "language": "python",
   "name": "pcs-3.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
